name: SEACE CSV ZIP -> BigQuery (3 meses, TODO STRING, union en BQ)

on:
  workflow_dispatch: {}

jobs:
  seace_3m_text:
    runs-on: ubuntu-latest

    env:
      PROJECT_ID: heroic-ruler-481618-e5
      DATASET: github_actions
      MONTHS: "2025-11 2025-12 2026-01"
      PYTHONUNBUFFERED: "1"

    steps:
      - uses: actions/checkout@v4

      - name: Auth Google
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: heroic-ruler-481618-e5

      - name: Crear dataset si no existe
        run: |
          set -euxo pipefail
          bq --project_id="$PROJECT_ID" mk --dataset "$PROJECT_ID:$DATASET" || true

      - name: Limpiar runner
        run: |
          set -euxo pipefail
          mkdir -p tmp data
          rm -rf tmp/* data/*

      # =========================
      # DESCARGA + EXTRACCIÓN
      # =========================
      - name: Descargar ZIPs y extraer CSV
        run: |
          set -euxo pipefail
          python - <<'PY'
          import os, zipfile, subprocess
          from pathlib import Path

          tmp = Path("tmp"); tmp.mkdir(exist_ok=True)
          months = os.environ["MONTHS"].split()

          for ym in months:
              y,m = ym.split("-")
              url = f"https://contratacionesabiertas.oece.gob.pe/api/v1/file/seace_v3/csv/{y}/{m}"
              zipf = tmp / f"seace_{y}_{m}.zip"
              out  = tmp / f"unzipped_{y}_{m}"
              out.mkdir(exist_ok=True)

              subprocess.check_call(["curl","-L","-f",url,"-o",zipf])
              with zipfile.ZipFile(zipf) as z:
                  z.extractall(out)

              print(f"[OK] {ym} CSVs: {len(list(out.glob('*.csv')))}")
          PY

      # =========================
      # NORMALIZAR + SCHEMA STRING
      # =========================
      - name: Normalizar headers y generar schema TODO STRING
        run: |
          set -euxo pipefail
          python - <<'PY'
          import re, json, os
          from pathlib import Path

          tmp = Path("tmp")
          data = Path("data"); data.mkdir(exist_ok=True)
          months = os.environ["MONTHS"].split()

          def norm(s):
              s = s.replace("/","_").replace(" ","_").replace("-","_")
              s = re.sub(r"[^A-Za-z0-9_]", "_", s)
              s = re.sub(r"_+","_",s).strip("_")
              return s if not s[0].isdigit() else "c_"+s

          for ym in months:
              y,m = ym.split("-")
              src = tmp / f"unzipped_{y}_{m}"
              for f in src.glob("*.csv"):
                  lines = f.read_text(errors="replace").splitlines(True)
                  if not lines: continue

                  cols = [norm(c) for c in lines[0].rstrip().split(",")]
                  lines[0] = ",".join(cols) + "\n"

                  table = f"{norm(f.stem)}_{y}_{m}"
                  out_csv = data / f"{table}.csv"
                  out_csv.write_text("".join(lines))

                  schema = [{"name":c,"type":"STRING","mode":"NULLABLE"} for c in cols]
                  (data / f"{table}.schema.json").write_text(json.dumps(schema))

                  print(f"[OK] {table}")
          PY

      # =========================
      # CARGA A BIGQUERY
      # =========================
      - name: Cargar CSVs a BigQuery (tablas mensuales)
        run: |
          set -euxo pipefail
          for f in data/*.csv; do
            table=$(basename "$f" .csv)
            bq --project_id="$PROJECT_ID" load \
              --source_format=CSV \
              --skip_leading_rows=1 \
              --allow_quoted_newlines \
              --max_bad_records=0 \
              --replace \
              "$DATASET.$table" \
              "$f" \
              "data/$table.schema.json"
            echo "[OK] cargado $table"
          done

      # =========================
      # UNIÓN FINAL EN BIGQUERY
      # =========================
      - name: Unir tablas mensuales por nombre base (BigQuery)
        run: |
          set -euxo pipefail
          bq --project_id="$PROJECT_ID" query --use_legacy_sql=false "
          DECLARE ds STRING DEFAULT '$DATASET';

          FOR t IN (
            SELECT DISTINCT REGEXP_REPLACE(table_name, r'_[0-9]{4}_[0-9]{2}$','') base
            FROM \`${PROJECT_ID}.${DATASET}.INFORMATION_SCHEMA.TABLES\`
            WHERE table_type='BASE TABLE'
          ) DO

            EXECUTE IMMEDIATE (
              SELECT 'CREATE OR REPLACE TABLE \`' || ds || '.' || t.base || '\` AS ' ||
                     STRING_AGG(
                       'SELECT * FROM \`' || ds || '.' || table_name || '\`',
                       ' UNION ALL '
                     )
              FROM \`${PROJECT_ID}.${DATASET}.INFORMATION_SCHEMA.TABLES\`
              WHERE REGEXP_CONTAINS(table_name, r'^' || t.base || '_[0-9]{4}_[0-9]{2}$')
            );

          END FOR;
          "
