name: SEACE CSV ZIP -> BigQuery (3 meses, TODO TEXTO, unión en BQ)

on:
  workflow_dispatch: {}

jobs:
  seace_3m_text:
    runs-on: ubuntu-latest

    env:
      PROJECT_ID: heroic-ruler-481618-e5
      DATASET: github_actions
      MONTHS: "2025-11 2025-12 2026-01"
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Auth Google
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: heroic-ruler-481618-e5

      - name: Crear dataset si no existe
        shell: bash
        run: |
          bq --project_id="$PROJECT_ID" mk --dataset "$PROJECT_ID:$DATASET" || true

      - name: Limpiar runner
        shell: bash
        run: |
          rm -rf data tmp
          mkdir data tmp

      # =========================
      # DESCARGA + EXTRACCIÓN
      # =========================
      - name: Descargar ZIPs y extraer CSVs
        shell: bash
        run: |
          python - <<'PY'
          import os, zipfile, subprocess
          from pathlib import Path

          MONTHS = os.environ["MONTHS"].split()
          tmp = Path("tmp"); tmp.mkdir(exist_ok=True)

          for ym in MONTHS:
              y, m = ym.split("-")
              url = f"https://contratacionesabiertas.oece.gob.pe/api/v1/file/seace_v3/csv/{y}/{m}"
              zip_path = tmp / f"{y}_{m}.zip"
              out_dir = tmp / f"{y}_{m}"
              out_dir.mkdir(exist_ok=True)

              subprocess.check_call(["curl", "-L", "-sS", url, "-o", zip_path])

              with zipfile.ZipFile(zip_path) as z:
                  z.extractall(out_dir)
          PY

      # =========================
      # NORMALIZAR HEADERS + TODO STRING
      # =========================
      - name: Normalizar headers y preparar CSVs
        shell: bash
        run: |
          python - <<'PY'
          import os, re, json
          from pathlib import Path

          def norm(s):
              s = re.sub(r'[^A-Za-z0-9_]', '_', s.strip())
              s = re.sub(r'_+', '_', s)
              if s[0].isdigit(): s = "c_" + s
              return s

          tmp = Path("tmp")
          data = Path("data"); data.mkdir(exist_ok=True)

          for mdir in tmp.iterdir():
              if not mdir.is_dir(): continue
              y, m = mdir.name.split("_")

              for csv in mdir.glob("*.csv"):
                  table = f"{csv.stem}_{y}_{m}"
                  lines = csv.read_text(encoding="utf-8", errors="replace").splitlines(True)

                  headers = [norm(h) for h in lines[0].split(",")]
                  lines[0] = ",".join(headers) + "\n"

                  out_csv = data / f"{table}.csv"
                  out_csv.write_text("".join(lines), encoding="utf-8")

                  schema = [{"name": h, "type": "STRING"} for h in headers]
                  (data / f"{table}.schema.json").write_text(json.dumps(schema))
          PY

      # =========================
      # CARGA A BIGQUERY
      # =========================
      - name: Cargar CSVs a BigQuery (TODO STRING)
        shell: bash
        run: |
          set -e
          for csv in data/*.csv; do
            table=$(basename "$csv" .csv)
            bq --project_id="$PROJECT_ID" load \
              --source_format=CSV \
              --skip_leading_rows=1 \
              --max_bad_records=0 \
              "$DATASET.$table" \
              "$csv" \
              "data/$table.schema.json"
          done

      # =========================
      # UNIÓN FINAL EN BIGQUERY
      # =========================
      - name: Unir tablas mensuales en BigQuery (columnas faltantes = NULL)
        shell: bash
        run: |
          bq --project_id="$PROJECT_ID" query --use_legacy_sql=false <<SQL
          DECLARE ds STRING DEFAULT '${DATASET}';

          FOR fam IN (
            SELECT DISTINCT REGEXP_REPLACE(table_name, r'_[0-9]{4}_[0-9]{2}$', '') base
            FROM \`${PROJECT_ID}.${DATASET}.INFORMATION_SCHEMA.TABLES\`
          ) DO

            EXECUTE IMMEDIATE (
              WITH t AS (
                SELECT table_name
                FROM \`${PROJECT_ID}.${DATASET}.INFORMATION_SCHEMA.TABLES\`
                WHERE REGEXP_CONTAINS(table_name, CONCAT('^', fam.base, '_[0-9]{4}_[0-9]{2}$'))
              ),
              c AS (
                SELECT DISTINCT column_name
                FROM \`${PROJECT_ID}.${DATASET}.INFORMATION_SCHEMA.COLUMNS\`
                WHERE table_name IN (SELECT table_name FROM t)
              )
              SELECT
                'CREATE OR REPLACE TABLE `${PROJECT_ID}.${DATASET}.' || fam.base || '` AS ' ||
                STRING_AGG(
                  'SELECT ' ||
                  (SELECT STRING_AGG(
                     IF(col.column_name IN (
                        SELECT column_name
                        FROM \`${PROJECT_ID}.${DATASET}.INFORMATION_SCHEMA.COLUMNS\`
                        WHERE table_name = t.table_name
                     ),
                     '`' || col.column_name || '`',
                     'NULL AS `' || col.column_name || '`'
                     )
                  )
                  FROM c col
                  ) ||
                  ' FROM `${PROJECT_ID}.${DATASET}.' || t.table_name || '`',
                  ' UNION ALL '
                )
              FROM t
            );

          END FOR;
          SQL
