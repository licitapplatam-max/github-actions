name: SEACE CSV ZIP -> BigQuery (3 meses FINAL)

on:
  workflow_dispatch: {}

jobs:
  seace_final:
    runs-on: ubuntu-latest

    env:
      PROJECT_ID: heroic-ruler-481618-e5
      DATASET: github_actions
      MONTHS: "2025-11 2025-12 2026-01"

    steps:
      - uses: actions/checkout@v4

      - name: Auth Google
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: heroic-ruler-481618-e5

      - name: Crear dataset si no existe
        run: |
          bq --project_id="$PROJECT_ID" mk --dataset "$PROJECT_ID:$DATASET" || true

      - name: Limpiar runner
        run: |
          mkdir -p tmp data
          rm -rf tmp/* data/*

      # -------------------------------------------------------
      # 1) DESCARGA + CONTEO REAL
      # -------------------------------------------------------
      - name: Descargar ZIPs y contar filas reales
        run: |
          python - <<'PY'
          import os, zipfile, csv
          from pathlib import Path

          MONTHS = os.environ["MONTHS"].split()
          tmp = Path("tmp"); tmp.mkdir(exist_ok=True)

          def count_rows(csv_path):
              with open(csv_path, newline='', encoding='utf-8', errors='replace') as f:
                  r = csv.reader(f)
                  next(r, None)
                  return sum(1 for _ in r)

          total_all = 0

          for ym in MONTHS:
              y,m = ym.split("-")
              url = f"https://contratacionesabiertas.oece.gob.pe/api/v1/file/seace_v3/csv/{y}/{m}"
              zipf = tmp / f"seace_{y}_{m}.zip"
              out  = tmp / f"unzipped_{y}_{m}"
              os.system(f"curl -L -sS '{url}' -o '{zipf}'")
              out.mkdir(exist_ok=True)

              with zipfile.ZipFile(zipf) as z:
                  z.extractall(out)

              print(f"\nMES {ym}")
              month_sum = 0
              for f in sorted(out.glob("*.csv")):
                  c = count_rows(f)
                  month_sum += c
                  print(f"{f.name:35s} rows={c}")
              total_all += month_sum
              print(f"TOTAL MES {ym}: {month_sum}")

          print(f"\nTOTAL 3 MESES: {total_all}")
          PY

      # -------------------------------------------------------
      # 2) CARGA A BIGQUERY (SIN DESCARTAR FILAS)
      # -------------------------------------------------------
      - name: Cargar CSVs a BigQuery (espera real)
        run: |
          python - <<'PY'
          import os, re, time, subprocess
          from pathlib import Path

          PROJECT = os.environ["PROJECT_ID"]
          DATASET = os.environ["DATASET"]
          MONTHS  = os.environ["MONTHS"].split()

          tmp  = Path("tmp")
          data = Path("data"); data.mkdir(exist_ok=True)

          def norm(h):
              seen = {}
              out = []
              for c in h.rstrip().split(","):
                  c = re.sub(r"[^A-Za-z0-9_]", "_", c.strip())
                  c = re.sub(r"_+", "_", c).strip("_") or "col"
                  if c[0].isdigit(): c = "c_" + c
                  i = seen.get(c,0)
                  seen[c]=i+1
                  out.append(c if i==0 else f"{c}_{i}")
              return ",".join(out)+"\n"

          for ym in MONTHS:
              y,m = ym.split("-")
              src = tmp / f"unzipped_{y}_{m}"

              for csvf in sorted(src.glob("*.csv")):
                  base = re.sub(r"[^A-Za-z0-9_]", "_", csvf.stem)
                  table = f"{base}_{y}_{m}"
                  clean = data / f"{table}.csv"

                  lines = csvf.read_text(errors="replace").splitlines(True)
                  lines[0] = norm(lines[0])
                  clean.write_text("".join(lines))

                  job = f"load_{table}_{int(time.time())}"
                  cmd = [
                      "bq", f"--project_id={PROJECT}",
                      "load",
                      "--job_id", job,
                      "--nosync",
                      "--source_format=CSV",
                      "--skip_leading_rows=1",
                      "--autodetect",
                      "--max_bad_records=0",
                      "--replace",
                      f"{DATASET}.{table}",
                      str(clean)
                  ]

                  subprocess.run(cmd, check=True)
                  print(f"[START] {job}")

                  while True:
                      r = subprocess.run(
                          ["bq", f"--project_id={PROJECT}", "wait", "-j", f"{PROJECT}:{job}"],
                          capture_output=True
                      )
                      if r.returncode == 0:
                          print(f"[OK] {job}")
                          break
                      print(f"[HB] {job} sigue...")
                      time.sleep(20)
          PY

      # -------------------------------------------------------
      # 3) CREAR VIEWS BASE
      # -------------------------------------------------------
      - name: Crear views base
        run: |
          bq --project_id="$PROJECT_ID" query --use_legacy_sql=false "
          DECLARE p STRING DEFAULT '${PROJECT_ID}';
          DECLARE d STRING DEFAULT '${DATASET}';

          FOR t IN (
            SELECT DISTINCT REGEXP_REPLACE(table_name, r'_[0-9]{4}_[0-9]{2}$','') base
            FROM \`${PROJECT_ID}.${DATASET}.INFORMATION_SCHEMA.TABLES\`
          ) DO
            EXECUTE IMMEDIATE FORMAT(
              'CREATE OR REPLACE VIEW `%s.%s.%s` AS
               SELECT * FROM `%s.%s.%s_*`',
              p,d,t.base,p,d,t.base
            );
          END FOR;
          "
