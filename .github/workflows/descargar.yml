name: Descargar CSV/ZIP SEACE y cargar a BigQuery (1 mes)

on:
  workflow_dispatch: {}

jobs:
  fetch_csv_bq:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout (chék-aut)
        uses: actions/checkout@v4

      - name: Auth Google (gúgol)
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud (yi-kláud)
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: heroic-ruler-481618-e5

      # Paso 1: Limpieza REAL de data/
      - name: Limpiar carpeta data (real)
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p data tmp
          rm -rf data/*
          rm -rf tmp/*
          echo "data/ limpio:"
          ls -lah data

      # Paso 2: Descargar (puede venir ZIP o CSV) y dejar CSV en data/
      - name: Descargar y obtener CSV final
        shell: bash
        run: |
          set -euxo pipefail

          YEAR="2026"
          MONTH="01"

          URL="https://contratacionesabiertas.oece.gob.pe/api/v1/file/seace_v3/csv/${YEAR}/${MONTH}"
          RAW="tmp/seace_${YEAR}_${MONTH}.bin"
          OUT="data/seace_v3_${YEAR}_${MONTH}.csv"

          curl -L -f -sS "$URL" -o "$RAW"
          test -s "$RAW"

          echo "Tipo descargado:"
          file "$RAW"

          if file "$RAW" | grep -qi "zip"; then
            echo "Vino como ZIP, extrayendo..."
            unzip -o "$RAW" -d tmp/unzipped
            CSV_IN="$(find tmp/unzipped -type f -iname '*.csv' | head -n 1)"
            if [ -z "$CSV_IN" ]; then
              echo "ERROR: no hay .csv dentro del ZIP"
              exit 1
            fi
            cp "$CSV_IN" "$OUT"
          else
            cp "$RAW" "$OUT"
          fi

          echo "CSV final:"
          ls -lh "$OUT"
          echo "Primeras 3 líneas:"
          head -n 3 "$OUT"

      # Paso 3: Quitar ASCII 0 (NUL) si existe
      - name: Quitar ASCII 0 (NUL) si existe
        shell: bash
        run: |
          set -euxo pipefail
          IN="data/seace_v3_2026_01.csv"
          OUT="tmp/no_nul.csv"

          # quitar NUL siempre (si no hay, no pasa nada)
          tr -d '\000' < "$IN" > "$OUT"
          test -s "$OUT"

          echo "Preview sin NUL:"
          head -n 2 "$OUT"

      # Paso 4: Normalizar HEADERS (aquí arreglamos el / que rompe BigQuery)
      - name: Normalizar headers para BigQuery
        shell: bash
        run: |
          set -euxo pipefail

          IN="tmp/no_nul.csv"
          OUT="data/seace_v3_2026_01_clean.csv"

          python - <<'PY'
          import re

          inp = "tmp/no_nul.csv"
          out = "data/seace_v3_2026_01_clean.csv"

          with open(inp, "r", encoding="utf-8", errors="replace") as f:
            lines = f.readlines()

          if not lines:
            raise SystemExit("CSV vacío")

          header = lines[0].rstrip("\n\r")

          # Split simple por coma: en estos CSV los headers NO deberían traer comas dentro de comillas
          cols = header.split(",")

          fixed = []
          seen = {}
          for c in cols:
            c = c.strip()

            # Reglas de normalización
            c = c.replace("/", "_")
            c = c.replace(" ", "_")
            c = c.replace("-", "_")
            c = re.sub(r"[^A-Za-z0-9_]", "_", c)
            c = re.sub(r"_+", "_", c).strip("_")

            if not c:
              c = "col"

            if c[0].isdigit():
              c = "c_" + c

            # Evitar duplicados (muy importante)
            base = c
            k = seen.get(base, 0)
            if k > 0:
              c = f"{base}_{k}"
            seen[base] = k + 1

            fixed.append(c)

          lines[0] = ",".join(fixed) + "\n"

          with open(out, "w", encoding="utf-8", newline="") as g:
            g.writelines(lines)

          print("Header original (primeros 200 chars):")
          print(header[:200])
          print("Header normalizado (primeros 200 chars):")
          print(lines[0][:200])
          print("Columnas:", len(fixed))
          PY

          echo "Preview final:"
          head -n 2 "$OUT"
          ls -lh "$OUT"

      # Paso 5: Cargar a BigQuery
      - name: Cargar a BigQuery (big-kuéri)
        shell: bash
        run: |
          set -euxo pipefail

          PROJECT_ID="heroic-ruler-481618-e5"
          DATASET="github_actions"
          TABLE="seace_v3_2026_01"
          FILE="data/seace_v3_2026_01_clean.csv"

          bq --project_id="$PROJECT_ID" load \
            --source_format=CSV \
            --autodetect \
            --skip_leading_rows=1 \
            --allow_quoted_newlines \
            --allow_jagged_rows \
            --max_bad_records=5000 \
            --replace \
            "${DATASET}.${TABLE}" \
            "$FILE"

          echo "OK. Tabla lista: ${DATASET}.${TABLE}"
